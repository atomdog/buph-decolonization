{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "018662d1-52bf-44e1-82b9-38a3c754d5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: folium in /home/aidan/.local/lib/python3.10/site-packages (0.17.0)\n",
      "Requirement already satisfied: numpy in /home/aidan/.local/lib/python3.10/site-packages (from folium) (1.25.2)\n",
      "Requirement already satisfied: xyzservices in /home/aidan/.local/lib/python3.10/site-packages (from folium) (2024.6.0)\n",
      "Requirement already satisfied: requests in /home/aidan/.local/lib/python3.10/site-packages (from folium) (2.31.0)\n",
      "Requirement already satisfied: jinja2>=2.9 in /home/aidan/.local/lib/python3.10/site-packages (from folium) (3.1.2)\n",
      "Requirement already satisfied: branca>=0.6.0 in /home/aidan/.local/lib/python3.10/site-packages (from folium) (0.7.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/aidan/.local/lib/python3.10/site-packages (from jinja2>=2.9->folium) (2.1.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/aidan/.local/lib/python3.10/site-packages (from requests->folium) (2.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->folium) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/aidan/.local/lib/python3.10/site-packages (from requests->folium) (3.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->folium) (2020.6.20)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: networkx in /home/aidan/.local/lib/python3.10/site-packages (3.2.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: haversine in /home/aidan/.local/lib/python3.10/site-packages (2.8.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /home/aidan/.local/lib/python3.10/site-packages (1.25.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/aidan/.local/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/aidan/.local/lib/python3.10/site-packages (from pandas) (1.25.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/aidan/.local/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/aidan/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install folium\n",
    "!pip3 install networkx\n",
    "!pip3 install haversine\n",
    "!pip3 install numpy\n",
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c6b2314-ed6d-4b1e-8f1f-626119ae62c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in /home/aidan/.local/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/lib/python3/dist-packages (from seaborn) (3.5.1)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/aidan/.local/lib/python3.10/site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/aidan/.local/lib/python3.10/site-packages (from seaborn) (1.25.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/aidan/.local/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/aidan/.local/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=1.2->seaborn) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15879927-8348-41b8-89c5-fbe9363e4cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import networkx as nx\n",
    "import folium\n",
    "from haversine import haversine\n",
    "import storage\n",
    "from folium.plugins import MarkerCluster\n",
    "from folium.plugins import HeatMap\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f974024-a846-4e40-afd9-2802e3af5da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "departments = storage.retrieve_all_departments()\n",
    "article_dept_links = storage.get_article_department_links()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2ed8e0-e2a2-40a4-9768-1617b9b37949",
   "metadata": {},
   "source": [
    "## Absolute Department Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb9feff-fa29-49b3-ad93-9bdbec5511b2",
   "metadata": {},
   "source": [
    "A location heatmap - measuring the quantity of departments detected in a given area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20f1f53b-0f2a-4371-b92b-16655fa3f3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_heatmap(departments, article_dept_links):\n",
    "    # Initialize a folium map centered around the average latitude and longitude\n",
    "    latitudes = [dept[2] for dept in departments]\n",
    "    longitudes = [dept[3] for dept in departments]\n",
    "    map_center = [sum(latitudes) / len(latitudes), sum(longitudes) / len(longitudes)]\n",
    "    \n",
    "    folium_map = folium.Map(location=map_center, zoom_start=2)\n",
    "\n",
    "    # Create a dictionary to count the number of connections for each department\n",
    "    dept_connections = {dept[0]: 0 for dept in departments}\n",
    "    for link in article_dept_links:\n",
    "        dept1_id, dept2_id, _, _ = link\n",
    "        dept_connections[dept1_id] += 1\n",
    "        dept_connections[dept2_id] += 1\n",
    "\n",
    "    # Create heatmap data\n",
    "    heat_data = []\n",
    "    for dept in departments:\n",
    "        dept_id, _, lat, lon = dept\n",
    "        if lat != 0.0 and lon != 0.0:  # Ensure valid coordinates\n",
    "            intensity = dept_connections[dept_id]\n",
    "            heat_data.append([lat, lon, intensity])\n",
    "\n",
    "    # Add the heatmap layer to the map\n",
    "    HeatMap(heat_data, max_zoom=15).add_to(folium_map)\n",
    "\n",
    "    return folium_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01d9f82b-7b9b-4fe3-9d1f-53308d32e9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"600\"\n",
       "            src=\"department_heatmap.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7d7300993ce0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "departments = storage.retrieve_all_departments()\n",
    "article_dept_links = storage.get_article_department_links()\n",
    "\n",
    "# Create the heatmap\n",
    "heatmap = create_heatmap(departments, article_dept_links)\n",
    "\n",
    "# Display the heatmap in a Jupyter notebook\n",
    "heatmap.save(\"department_heatmap.html\")\n",
    "from IPython.display import IFrame\n",
    "IFrame('department_heatmap.html', width=1000, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d60f22-a275-48fa-bfde-eb92886a4673",
   "metadata": {},
   "source": [
    "## Absolute Network Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e8f5f2db-4948-4bcc-bb10-60496dd44c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"department_network_map_colored.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7d7301766240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import folium\n",
    "from IPython.display import display, IFrame\n",
    "import storage\n",
    "from folium.plugins import MarkerCluster\n",
    "import random\n",
    "\n",
    "# Function to generate a random color for each journal\n",
    "def generate_random_color():\n",
    "    return \"#{:06x}\".format(random.randint(0, 0xFFFFFF))\n",
    "\n",
    "# Create NetworkX graph from department data and shared articles\n",
    "def create_graph(departments, article_dept_links):\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add departments as nodes\n",
    "    for dept in departments:\n",
    "        dept_id, name, lat, lon = dept\n",
    "        G.add_node(dept_id, name=name, lat=lat, lon=lon)\n",
    "    \n",
    "    # Add edges based on shared articles\n",
    "    for link in article_dept_links:\n",
    "        dept1_id, dept2_id, article_id, journal_title = link\n",
    "        if G.has_edge(dept1_id, dept2_id):\n",
    "            G[dept1_id][dept2_id]['weight'] += 1\n",
    "            G[dept1_id][dept2_id]['articles'].append((article_id, journal_title))\n",
    "        else:\n",
    "            G.add_edge(dept1_id, dept2_id, weight=1, articles=[(article_id, journal_title)], journal=journal_title)\n",
    "    \n",
    "    return G\n",
    "\n",
    "# Create Folium map with department connections and metrics\n",
    "def create_map(G):\n",
    "    # Create base map with clustering\n",
    "    m = folium.Map(location=[0, 0], zoom_start=2)\n",
    "    marker_cluster = MarkerCluster().add_to(m)\n",
    "    \n",
    "    # Create a color mapping for each journal\n",
    "    journal_colors = {}\n",
    "    \n",
    "    # Add nodes (departments) to the map\n",
    "    for node in G.nodes(data=True):\n",
    "        node_id = node[0]\n",
    "        node_data = node[1]\n",
    "        name = node_data['name']\n",
    "        lat = node_data['lat']\n",
    "        lon = node_data['lon']\n",
    "        \n",
    "        popup_text = f\"Department: {name}\"\n",
    "        \n",
    "        folium.Marker(\n",
    "            location=[lat, lon],\n",
    "            popup=popup_text,\n",
    "            icon=folium.Icon(color='blue')\n",
    "        ).add_to(marker_cluster)\n",
    "    \n",
    "    # Add edges (connections) to the map with colors based on journal\n",
    "    for edge in G.edges(data=True):\n",
    "        dept1 = G.nodes[edge[0]]\n",
    "        dept2 = G.nodes[edge[1]]\n",
    "        points = [(dept1['lat'], dept1['lon']), (dept2['lat'], dept2['lon'])]\n",
    "        \n",
    "        journal_title = edge[2]['journal']\n",
    "        \n",
    "        # Assign a color to each journal\n",
    "        if journal_title not in journal_colors:\n",
    "            journal_colors[journal_title] = generate_random_color()\n",
    "        \n",
    "        # Get the color for this journal\n",
    "        color = journal_colors[journal_title]\n",
    "        \n",
    "        folium.PolyLine(points, color=color, weight=edge[2]['weight'], tooltip=journal_title).add_to(m)\n",
    "    \n",
    "    return m\n",
    "\n",
    "# Main execution\n",
    "departments = storage.retrieve_all_departments()\n",
    "article_dept_links = storage.get_article_department_links()\n",
    "G = create_graph(departments, article_dept_links)\n",
    "map_ = create_map(G)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "map_.save(\"department_network_map_colored.html\")\n",
    "\n",
    "# Display the map directly in the notebook\n",
    "display(IFrame('department_network_map_colored.html', width=800, height=600))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e2a123-adc6-48a9-87e0-3aaeb49b8b31",
   "metadata": {},
   "source": [
    "## Absolute Department Prevalence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f57e8e-9ffb-48ba-ab25-90d34a3c1b7d",
   "metadata": {},
   "source": [
    "The absolute number of connections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "462f0e01-2cf6-4ff9-ad82-64ddd81460f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked Departments by Prevalence:\n",
      "1 Department of Microbiology and Immunology, University of Melbourne, Peter Doherty Institute for Infection and Immunity, Melbourne, VIC 3000, Australia.  / Department of Microbiology and Immunology, University of Melbourne, Peter Doherty Institute for Infection and Immunity, Melbourne, VIC 3000, Australia. / Department of Anatomy and Physiology, University of Melbourne, Parkville, VIC 3010, Australia. / Department of Microbiology and Immunology, University of Melbourne, Peter Doherty Institute for Infection and Immunity, Melbourne, VIC 3000, Australia\n",
      "2 Regeneron Genetics Center, Tarrytown, NY, USA.\n",
      "3 AncestryDNA, Lehi, UT, USA.\n",
      "4 Department of HostMicrobe Interactions, St. Jude Children's Research Hospital, Memphis, TN 38105, USA / Department of HostMicrobe Interactions, St. Jude Children's Research Hospital, Memphis, TN 38105, USA. / Department of Infectious Diseases, St. Jude Children's Research Hospital, Memphis, TN 38105, USA. / Center for Infectious Diseases Research, St. Jude Children's Research Hospital, Memphis, TN 38105, USA\n",
      "5 Geisinger, Danville, PA, USA.\n",
      "6 Department of Chemistry, Stanford University, Stanford, CA 94305, USA. / Department of Neurosurgery, Stanford University School of Medicine, Stanford, CA 94305, USA / Transgenic, Knockout and Tumor model Center (TKTC), Cancer Institute, Stanford University School of Medicine, Stanford, CA 94305, USA. / Department of Chemistry, Stanford University, Stanford, CA 94305, USA.  / Department of Neurosurgery, Stanford University School of Medicine, Stanford, CA 94305, USA. / Behavioral and Functional Neuroscience Laboratory, Stanford University School of Medicine, Stanford, CA 94305, USA. / Department of Neurosurgery, Stanford University School of Medicine, Stanford, CA 94305, USA. \n",
      "7 Department of Cardiothoracic Surgery, Royal Children's Hospital, University of Melbourne, Melbourne Centre for Cardiovascular Genomics and Regenerative Medicine, Parkville, VIC 3052, Australia. / Walter Eliza Hall Institute of Medical Research, Parkville, VIC 3052, Australia\n",
      "8 UN Human Settlements Programme, Nairobi, Kenya. / Nairobi City County Department of Health, Nairobi, Kenya. / Young Positive Women Voices, Nairobi, Kenya.\n",
      "9 Bioimaging Facility, Netherlands Cancer Institute, 1066CX Amsterdam, the Netherlands. / Division of Tumour Biology and Immunology, Oncode Institute, The Netherlands Cancer Institute, 1066CX Amsterdam, the Netherlands.  / Division of Tumour Biology and Immunology, Oncode Institute, The Netherlands Cancer Institute, 1066CX Amsterdam, the Netherlands. / Division of Gene Regulation, The Netherlands Cancer Institute, 1066CX Amsterdam, the Netherlands.\n",
      "10 Department of Cardiovascular Medicine and the Gonda Vascular Center, Mayo Clinic, Rochester, MN, USA. kullo.iftikhar@mayo.edu. / Kogod Center on Aging and Division of Endocrinology, Mayo Clinic, Rochester, MN, USA. / Mayo Clinic, Department of Physiology and Biomedical Engineering, Robert and Arlene Kogod Center on Aging, Rochester, MN, USA. / Department of Biochemistry and Molecular Biology, Department of Pediatric and Adolescent Medicine, Robert and Arlene Kogod Center on Aging, Mayo Clinic, 200 First Steet SW, Rochester, MN 55905, USA. / Department of Physiology and Biomedical Engineering, Mayo Clinic, Rochester, MN, USA\n"
     ]
    }
   ],
   "source": [
    "# Function to rank departments based on prevalence\n",
    "def rank_departments_by_prevalence(departments, article_dept_links):\n",
    "    # Create a dictionary to count the number of connections for each department\n",
    "    dept_connections = {dept[0]: 0 for dept in departments}\n",
    "    \n",
    "    # Count the number of connections for each department\n",
    "    for link in article_dept_links:\n",
    "        dept1_id, dept2_id, _, _ = link\n",
    "        dept_connections[dept1_id] += 1\n",
    "        dept_connections[dept2_id] += 1\n",
    "\n",
    "    # Create a list of tuples (department_id, department_name, connection_count)\n",
    "    ranked_departments = [(dept[0], dept[1], dept_connections[dept[0]]) for dept in departments]\n",
    "    \n",
    "    # Sort the list based on connection_count in descending order\n",
    "    ranked_departments.sort(key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    return ranked_departments\n",
    "\n",
    "# Main execution\n",
    "departments = storage.retrieve_all_departments()\n",
    "article_dept_links = storage.get_article_department_links()\n",
    "\n",
    "# Rank the departments based on prevalence\n",
    "ranked_departments = rank_departments_by_prevalence(departments, article_dept_links)\n",
    "\n",
    "# Print the ranked departments\n",
    "print(\"Ranked Departments by Prevalence:\")\n",
    "#for rank, (dept_id, dept_name, connection_count) in enumerate(ranked_departments, 1):\n",
    "    #print(f\"{rank}. {dept_name} (ID: {dept_id}) - Connections: {connection_count}\")\n",
    "for i in range(0, 10):\n",
    "    print(str(i+1), df_ranked_departments.Department.iloc[i])\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e43021c-e6e3-462e-a266-300045029461",
   "metadata": {},
   "source": [
    "## Averaged Department Prevalence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b43b1f4-036c-41a2-ad48-33b06209b82a",
   "metadata": {},
   "source": [
    "The average number of connections per paper, per department (average collaboration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f2882c9c-53e1-45e2-9038-7c63b481af9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Department of Microbiology and Immunology, University of Melbourne, Peter Doherty Institute for Infection and Immunity, Melbourne, VIC 3000, Australia.  / Department of Microbiology and Immunology, University of Melbourne, Peter Doherty Institute for Infection and Immunity, Melbourne, VIC 3000, Australia. / Department of Anatomy and Physiology, University of Melbourne, Parkville, VIC 3010, Australia. / Department of Microbiology and Immunology, University of Melbourne, Peter Doherty Institute for Infection and Immunity, Melbourne, VIC 3000, Australia\n",
      "1 Regeneron Genetics Center, Tarrytown, NY, USA.\n",
      "2 AncestryDNA, Lehi, UT, USA.\n",
      "3 Department of HostMicrobe Interactions, St. Jude Children's Research Hospital, Memphis, TN 38105, USA / Department of HostMicrobe Interactions, St. Jude Children's Research Hospital, Memphis, TN 38105, USA. / Department of Infectious Diseases, St. Jude Children's Research Hospital, Memphis, TN 38105, USA. / Center for Infectious Diseases Research, St. Jude Children's Research Hospital, Memphis, TN 38105, USA\n",
      "4 Geisinger, Danville, PA, USA.\n",
      "5 Department of Chemistry, Stanford University, Stanford, CA 94305, USA. / Department of Neurosurgery, Stanford University School of Medicine, Stanford, CA 94305, USA / Transgenic, Knockout and Tumor model Center (TKTC), Cancer Institute, Stanford University School of Medicine, Stanford, CA 94305, USA. / Department of Chemistry, Stanford University, Stanford, CA 94305, USA.  / Department of Neurosurgery, Stanford University School of Medicine, Stanford, CA 94305, USA. / Behavioral and Functional Neuroscience Laboratory, Stanford University School of Medicine, Stanford, CA 94305, USA. / Department of Neurosurgery, Stanford University School of Medicine, Stanford, CA 94305, USA. \n",
      "6 Department of Cardiothoracic Surgery, Royal Children's Hospital, University of Melbourne, Melbourne Centre for Cardiovascular Genomics and Regenerative Medicine, Parkville, VIC 3052, Australia. / Walter Eliza Hall Institute of Medical Research, Parkville, VIC 3052, Australia\n",
      "7 UN Human Settlements Programme, Nairobi, Kenya. / Nairobi City County Department of Health, Nairobi, Kenya. / Young Positive Women Voices, Nairobi, Kenya.\n",
      "8 Bioimaging Facility, Netherlands Cancer Institute, 1066CX Amsterdam, the Netherlands. / Division of Tumour Biology and Immunology, Oncode Institute, The Netherlands Cancer Institute, 1066CX Amsterdam, the Netherlands.  / Division of Tumour Biology and Immunology, Oncode Institute, The Netherlands Cancer Institute, 1066CX Amsterdam, the Netherlands. / Division of Gene Regulation, The Netherlands Cancer Institute, 1066CX Amsterdam, the Netherlands.\n",
      "9 Department of Cardiovascular Medicine and the Gonda Vascular Center, Mayo Clinic, Rochester, MN, USA. kullo.iftikhar@mayo.edu. / Kogod Center on Aging and Division of Endocrinology, Mayo Clinic, Rochester, MN, USA. / Mayo Clinic, Department of Physiology and Biomedical Engineering, Robert and Arlene Kogod Center on Aging, Rochester, MN, USA. / Department of Biochemistry and Molecular Biology, Department of Pediatric and Adolescent Medicine, Robert and Arlene Kogod Center on Aging, Mayo Clinic, 200 First Steet SW, Rochester, MN 55905, USA. / Department of Physiology and Biomedical Engineering, Mayo Clinic, Rochester, MN, USA\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from haversine import haversine\n",
    "import storage\n",
    "\n",
    "def merge_departments_by_proximity(departments, distance_threshold=1.0):\n",
    "    merged_departments = []\n",
    "    visited = set()\n",
    "    \n",
    "    for i, dept1 in enumerate(departments):\n",
    "        if dept1[0] in visited:\n",
    "            continue\n",
    "        \n",
    "        merged_group = [dept1]\n",
    "        visited.add(dept1[0])\n",
    "        \n",
    "        for j, dept2 in enumerate(departments[i+1:], i+1):\n",
    "            if dept2[0] in visited:\n",
    "                continue\n",
    "            \n",
    "            distance = haversine((dept1[2], dept1[3]), (dept2[2], dept2[3]))\n",
    "            \n",
    "            if distance <= distance_threshold:\n",
    "                merged_group.append(dept2)\n",
    "                visited.add(dept2[0])\n",
    "        \n",
    "        merged_name = \" / \".join(set(d[1] for d in merged_group))\n",
    "        lat = merged_group[0][2]\n",
    "        lon = merged_group[0][3]\n",
    "        \n",
    "        merged_departments.append((merged_name, lat, lon, [d[0] for d in merged_group]))\n",
    "    \n",
    "    return merged_departments\n",
    "\n",
    "def create_dataframe(merged_departments, article_dept_links):\n",
    "    dept_collab = {dept[0]: {'connections': 0, 'papers': set()} for dept in merged_departments}\n",
    "    merged_dept_ids = {dept_id: dept[0] for dept in merged_departments for dept_id in dept[3]}\n",
    "    \n",
    "    # Collect unique papers and connections\n",
    "    for dept1, dept2, article_id, _ in article_dept_links:\n",
    "        merged_dept1 = merged_dept_ids.get(dept1)\n",
    "        merged_dept2 = merged_dept_ids.get(dept2)\n",
    "        \n",
    "        if merged_dept1 and merged_dept2:\n",
    "            if merged_dept1 != merged_dept2:\n",
    "                dept_collab[merged_dept1]['connections'] += 1\n",
    "                dept_collab[merged_dept2]['connections'] += 1\n",
    "                \n",
    "            dept_collab[merged_dept1]['papers'].add(article_id)\n",
    "            dept_collab[merged_dept2]['papers'].add(article_id)\n",
    "    \n",
    "    # Debugging: Print collected data\n",
    "    #print(\"Department Collaboration Data:\")\n",
    "    #for dept, data in dept_collab.items():\n",
    "        #print(f\"Department: {dept}, Connections: {data['connections']}, Papers: {len(data['papers'])}\")\n",
    "\n",
    "    # Calculate average connections per paper\n",
    "    for dept in dept_collab:\n",
    "        papers_count = len(dept_collab[dept]['papers'])\n",
    "        if papers_count > 0:\n",
    "            dept_collab[dept]['avg_connections_per_paper'] = dept_collab[dept]['connections'] / papers_count\n",
    "        else:\n",
    "            dept_collab[dept]['avg_connections_per_paper'] = 0\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame([\n",
    "        {'Department': dept, 'Avg Connections per Paper': data['avg_connections_per_paper']}\n",
    "        for dept, data in dept_collab.items()\n",
    "    ])\n",
    "    \n",
    "    df = df.sort_values(by='Avg Connections per Paper', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Main execution\n",
    "departments = storage.retrieve_all_departments()\n",
    "article_dept_links = storage.get_article_department_links()\n",
    "\n",
    "# Step 1: Merge departments by proximity\n",
    "merged_departments = merge_departments_by_proximity(departments, distance_threshold=1.0)\n",
    "\n",
    "# Step 2: Create and rank the DataFrame\n",
    "df_ranked_departments = create_dataframe(merged_departments, article_dept_links)\n",
    "\n",
    "# Display the ranked DataFrame\n",
    "for i in range(0, 10):\n",
    "    print(str(i+1), df_ranked_departments.Department.iloc[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872214e6-0331-415d-a9aa-c621b3e71536",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install shapely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f1190b-4b91-48dc-bd1a-3089a925187a",
   "metadata": {},
   "source": [
    "## Absolute Prevalence - Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b1c523ef-298a-4909-aae7-a6acb2251311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import folium\n",
    "import storage\n",
    "from shapely.geometry import shape, Point\n",
    "\n",
    "# Load the GeoJSON file\n",
    "with open('worldcountries.geojson') as f:\n",
    "    countries_geojson = json.load(f)\n",
    "    \n",
    "def get_country_from_point(lat, lon, countries_geojson):\n",
    "    point = Point(lon, lat)\n",
    "    for feature in countries_geojson['features']:\n",
    "        polygon = shape(feature['geometry'])\n",
    "        if polygon.contains(point):\n",
    "            return feature['properties']['COUNTRY']  # Use the correct property name for country\n",
    "    return None\n",
    "def count_articles_by_country(departments, countries_geojson):\n",
    "    country_article_count = {}\n",
    "    \n",
    "    for dept in departments:\n",
    "        dept_id, dept_name, lat, lon = dept\n",
    "        country = get_country_from_point(lat, lon, countries_geojson)\n",
    "        if country:\n",
    "            if country not in country_article_count:\n",
    "                country_article_count[country] = 0\n",
    "            articles = storage.retrieve_articles_by_department(dept_id)\n",
    "            country_article_count[country] += len(articles)\n",
    "    \n",
    "    return country_article_count\n",
    "def rank_countries_by_articles(country_article_count):\n",
    "    ranked_countries = sorted(country_article_count.items(), key=lambda item: item[1], reverse=True)\n",
    "    return ranked_countries\n",
    "def visualize_country_article_distribution(countries_geojson, country_article_count):\n",
    "    m = folium.Map(location=[0, 0], zoom_start=2)\n",
    "    \n",
    "    # Define a color scale based on the article count\n",
    "    max_articles = max(country_article_count.values())\n",
    "    min_articles = min(country_article_count.values())\n",
    "    color_scale = folium.LinearColormap(['green', 'yellow', 'red'], vmin=min_articles, vmax=max_articles)\n",
    "    \n",
    "    # Add countries to the map\n",
    "    for feature in countries_geojson['features']:\n",
    "        country_name = feature['properties']['COUNTRY']  # Adjust based on GeoJSON structure\n",
    "        article_count = country_article_count.get(country_name, 0)\n",
    "        \n",
    "        folium.GeoJson(\n",
    "            feature,\n",
    "            style_function=lambda feature, count=article_count: {\n",
    "                'fillColor': color_scale(count),\n",
    "                'color': 'black',\n",
    "                'weight': 0.5,\n",
    "                'fillOpacity': 0.7\n",
    "            },\n",
    "            tooltip=f'{country_name}: {article_count} articles'\n",
    "        ).add_to(m)\n",
    "    \n",
    "    m.add_child(color_scale)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1292edcd-4674-4cca-b865-a5e11eae178a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. United States: 240 articles\n",
      "2. Australia: 48 articles\n",
      "3. Netherlands: 42 articles\n",
      "4. Germany: 34 articles\n",
      "5. Spain: 31 articles\n",
      "6. Brazil: 25 articles\n",
      "7. United Kingdom: 22 articles\n",
      "8. China: 20 articles\n",
      "9. South Africa: 17 articles\n",
      "10. Kenya: 15 articles\n",
      "11. Switzerland: 13 articles\n",
      "12. Denmark: 12 articles\n",
      "13. Tanzania: 10 articles\n",
      "14. Italy: 8 articles\n",
      "15. Canada: 8 articles\n",
      "16. Austria: 7 articles\n",
      "17. Japan: 6 articles\n",
      "18. Madagascar: 6 articles\n",
      "19. India: 5 articles\n",
      "20. France: 5 articles\n",
      "21. Senegal: 5 articles\n",
      "22. Peru: 4 articles\n",
      "23. Mozambique: 4 articles\n",
      "24. Mali: 4 articles\n",
      "25. Ireland: 4 articles\n",
      "26. Norway: 4 articles\n",
      "27. Belgium: 3 articles\n",
      "28. Guatemala: 3 articles\n",
      "29. Slovenia: 2 articles\n",
      "30. Uganda: 2 articles\n",
      "31. Thailand: 2 articles\n",
      "32. Greece: 2 articles\n",
      "33. Argentina: 2 articles\n",
      "34. Philippines: 2 articles\n",
      "35. Zimbabwe: 2 articles\n",
      "36. Côte d'Ivoire: 2 articles\n",
      "37. Sweden: 2 articles\n",
      "38. Israel: 1 articles\n",
      "39. Poland: 1 articles\n",
      "40. Jamaica: 1 articles\n",
      "41. Croatia: 1 articles\n",
      "42. Malawi: 1 articles\n",
      "43. Cameroon: 1 articles\n",
      "44. Mexico: 1 articles\n",
      "45. Ukraine: 1 articles\n",
      "46. Honduras: 1 articles\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"country_article_distribution_map.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7d73003a5a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Load departments and articles\n",
    "departments = storage.retrieve_all_departments()\n",
    "\n",
    "# Step 2: Count articles by country\n",
    "country_article_count = count_articles_by_country(departments, countries_geojson)\n",
    "\n",
    "# Step 3: Rank countries by article count\n",
    "ranked_countries = rank_countries_by_articles(country_article_count)\n",
    "\n",
    "# Print the ranking\n",
    "for rank, (country, count) in enumerate(ranked_countries, 1):\n",
    "    print(f\"{rank}. {country}: {count} articles\")\n",
    "\n",
    "# Step 4: Visualize on a map (optional)\n",
    "map_ = visualize_country_article_distribution(countries_geojson, country_article_count)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "map_.save(\"country_article_distribution_map.html\")\n",
    "\n",
    "# Display the map in Jupyter\n",
    "display(IFrame('country_article_distribution_map.html', width=800, height=600))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab595df-99d8-4f17-8d04-99f98d367ee5",
   "metadata": {},
   "source": [
    "## Rank Countries by Frequency of Collaboration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e8385337-90f1-4fd6-b85d-ebcdf1ed1d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Countries by Collaborations:\n",
      "United States: 3296 collaborations\n",
      "Australia: 1352 collaborations\n",
      "United Kingdom: 972 collaborations\n",
      "South Africa: 630 collaborations\n",
      "Spain: 554 collaborations\n",
      "Kenya: 530 collaborations\n",
      "Switzerland: 502 collaborations\n",
      "Germany: 500 collaborations\n",
      "Italy: 426 collaborations\n",
      "Austria: 392 collaborations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"country_collaborations_map.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7d72e1eb9460>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import json\n",
    "import folium\n",
    "from shapely.geometry import shape, Point\n",
    "from collections import defaultdict\n",
    "import storage\n",
    "\n",
    "# Load the GeoJSON file\n",
    "with open('worldcountries.geojson') as f:\n",
    "    countries_geojson = json.load(f)\n",
    "\n",
    "# Function to get the country from geographic coordinates\n",
    "def get_country_from_point(lat, lon, countries_geojson):\n",
    "    point = Point(lon, lat)\n",
    "    for feature in countries_geojson['features']:\n",
    "        polygon = shape(feature['geometry'])\n",
    "        if polygon.contains(point):\n",
    "            return feature['properties']['COUNTRY']  # Adjust property name as per your GeoJSON structure\n",
    "    return None\n",
    "\n",
    "# Function to count collaborations between countries\n",
    "def count_country_collaborations(departments, article_dept_links, countries_geojson):\n",
    "    department_to_country = {}\n",
    "    country_collaboration_count = defaultdict(int)\n",
    "    \n",
    "    # Map each department to its respective country\n",
    "    for dept in departments:\n",
    "        dept_id, dept_name, lat, lon = dept\n",
    "        country = get_country_from_point(lat, lon, countries_geojson)\n",
    "        if country:\n",
    "            department_to_country[dept_id] = country\n",
    "    \n",
    "    # Analyze collaborations by checking if two departments (from different countries) share an article\n",
    "    for link in article_dept_links:\n",
    "        dept1_id, dept2_id, article_id, journal_title = link\n",
    "        country1 = department_to_country.get(dept1_id)\n",
    "        country2 = department_to_country.get(dept2_id)\n",
    "        \n",
    "        # Count only international collaborations\n",
    "        if country1 and country2 and country1 != country2:\n",
    "            country_collaboration_count[country1] += 1\n",
    "            country_collaboration_count[country2] += 1\n",
    "            \n",
    "    return country_collaboration_count\n",
    "\n",
    "# Function to rank countries based on collaborations\n",
    "def rank_countries_by_collaborations(country_collaboration_count):\n",
    "    ranked_countries = sorted(country_collaboration_count.items(), key=lambda item: item[1], reverse=True)\n",
    "    return ranked_countries\n",
    "\n",
    "# Function to visualize the collaborations on a map\n",
    "def visualize_country_collaborations(countries_geojson, country_collaboration_count):\n",
    "    m = folium.Map(location=[0, 0], zoom_start=2)\n",
    "    \n",
    "    # Define a color scale based on the collaboration count\n",
    "    max_collaborations = max(country_collaboration_count.values())\n",
    "    min_collaborations = min(country_collaboration_count.values())\n",
    "    color_scale = folium.LinearColormap(['green', 'yellow', 'red'], vmin=min_collaborations, vmax=max_collaborations)\n",
    "    \n",
    "    # Add countries to the map with collaboration counts\n",
    "    for feature in countries_geojson['features']:\n",
    "        country_name = feature['properties']['COUNTRY']  # Adjust property name as per your GeoJSON structure\n",
    "        collaboration_count = country_collaboration_count.get(country_name, 0)\n",
    "        \n",
    "        folium.GeoJson(\n",
    "            feature,\n",
    "            style_function=lambda feature, count=collaboration_count: {\n",
    "                'fillColor': color_scale(count),\n",
    "                'color': 'black',\n",
    "                'weight': 0.5,\n",
    "                'fillOpacity': 0.7\n",
    "            },\n",
    "            tooltip=f'{country_name}: {collaboration_count} collaborations'\n",
    "        ).add_to(m)\n",
    "    \n",
    "    m.add_child(color_scale)\n",
    "    return m\n",
    "\n",
    "# Main execution\n",
    "departments = storage.retrieve_all_departments()\n",
    "article_dept_links = storage.get_article_department_links()\n",
    "\n",
    "# Count collaborations\n",
    "country_collaboration_count = count_country_collaborations(departments, article_dept_links, countries_geojson)\n",
    "\n",
    "# Rank countries by collaborations\n",
    "ranked_countries = rank_countries_by_collaborations(country_collaboration_count)\n",
    "print(\"Top 10 Countries by Collaborations:\")\n",
    "for country, count in ranked_countries[:10]:\n",
    "    print(f'{country}: {count} collaborations')\n",
    "\n",
    "# Visualize the collaborations on a map\n",
    "collaboration_map = visualize_country_collaborations(countries_geojson, country_collaboration_count)\n",
    "\n",
    "# Save or display the map\n",
    "collaboration_map.save(\"country_collaborations_map.html\")\n",
    "display(IFrame('country_collaborations_map.html', width=800, height=600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d809db-ff9a-4bc9-8624-93a5ebaf87f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb274b4-ba5d-4857-babd-a385c8b28e74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
